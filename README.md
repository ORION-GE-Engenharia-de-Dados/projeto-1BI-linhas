# üìä (GE) Engenharia de Dados - Pipeline ETL com 1 Bilh√£o de Linhas

## üéØ Objetivo

Este projeto tem como objetivo desenvolver um pipeline completo de Engenharia de Dados, processando um dataset com 1 bilh√£o de linhas. O pipeline seguir√° todas as etapas de um processo profissional de ETL (Extra√ß√£o, Transforma√ß√£o e Carga), utilizando ferramentas **open source** amplamente utilizadas no mercado.

---

## üìå Contexto dos Dados

O dataset ser√° gerado sinteticamente. O tema pode ser escolhido entre os seguintes exemplos:

- **Financeiro:** Transa√ß√µes de cart√µes de cr√©dito
- **E-commerce:** Hist√≥rico de compras de usu√°rios
- **Mobilidade:** Corridas de aplicativos de transporte
- **IoT:** Leituras de sensores em tempo real

O formato final dos dados ser√° `.parquet`.

---

## üõ†Ô∏è Ferramentas do Pipeline

| Etapa | Ferramenta | Descri√ß√£o |
|-----|------|----|
| Gera√ß√£o de Dados | Python (Faker, Pandas, Polars) | Cria√ß√£o de dados sint√©ticos |
| Armazenamento | MinIO | Data Lake com camadas Bronze, Silver e Gold |
| Metastore de Metadados | Hive Metastore | Registro de schemas e tabelas para leitura via Trino |
| Explora√ß√£o Local | DuckDB | An√°lises explorat√≥rias e valida√ß√£o r√°pida local |
| Consulta Distribu√≠da | Trino (Presto) | Query engine distribu√≠do conectado ao MinIO e ao Hive Metastore |
| Transforma√ß√µes | DBT | Modelagem de dados com camadas staging, intermediate e mart |
| Orquestra√ß√£o | Apache Airflow | Agendamento e execu√ß√£o dos pipelines |
| (Opcional) Visualiza√ß√£o | Apache Superset ou Metabase | Cria√ß√£o de dashboards |

---

## üìç Estrutura de Camadas do Data Lake (MinIO)

Seguindo a arquitetura em camadas (medallion architecture), o Data Lake ser√° organizado da seguinte forma:

| Camada | Nome | Finalidade |
|---|---|---|
| **Bronze (Raw / Bruto)** | `landing-zone` | Armazena os dados exatamente como gerados, sem nenhum tratamento |
| **Silver (Processed / Limpo)** | `silver` | Dados tratados, com tipos corrigidos, dados inv√°lidos removidos e enriquecimentos b√°sicos aplicados |
| **Gold (Curated / Business Ready)** | `gold` | Dados prontos para an√°lises de neg√≥cio, com agrega√ß√µes, m√©tricas e modelos de dados finais |

---

## üìç Fases do Projeto

### Fase 1 ‚Äì Gera√ß√£o de Dados

- Desenvolver um script em Python para gerar um arquivo com 1 bilh√£o de linhas.
- Exemplos de colunas (tema financeiro):
  - `transaction_id`
  - `customer_id`
  - `transaction_amount`
  - `transaction_date`
  - `merchant_category`
  - `payment_method`
- Formato de sa√≠da: `.parquet`.
- Upload inicial dos dados na camada **Bronze (landing-zone)** no MinIO.
- Usar a imagem: `quay.io/minio/minio:RELEASE.2025-02-03T21-03-04Z-cpuv1`

---

### Fase 2 ‚Äì Explora√ß√£o de Dados com DuckDB

- Conectar ao arquivo localmente ou via S3 API com MinIO.
- Realizar an√°lises b√°sicas:
  - Contagem de linhas
  - Valida√ß√£o de tipos
  - Estat√≠sticas descritivas
- Tudo ser√° feito diretamente sobre os dados da camada **Bronze**.

---

### Fase 3 ‚Äì Registro de Metadados com Hive Metastore

- Instalar e configurar o **Hive Metastore**.
- Criar as tabelas externas correspondentes aos datasets armazenados no MinIO.
- Exemplo: criar tabelas externas apontando para o bucket `landing-zone`.

---

### Fase 4 ‚Äì Consulta Distribu√≠da com Trino

- Instalar e configurar o Trino.
- Conectar o Trino ao **Hive Metastore**.
- Criar cat√°logo S3 apontando para os buckets do MinIO.
- Executar queries SQL sobre os dados na **Bronze** e depois sobre as camadas transformadas (**Silver/Gold**).

---

### Fase 5 ‚Äì Transforma√ß√µes com DBT

- Estruturar o projeto DBT com tr√™s camadas de modelagem:

| Camada | Finalidade |
|----|----|
| **Staging** | Leitura da camada Bronze, ajustes de tipos e padroniza√ß√µes iniciais |
| **Intermediate** | Limpeza, enriquecimento, remo√ß√£o de duplicatas e filtros de qualidade |
| **Mart** | Cria√ß√£o de tabelas finais para consumo de neg√≥cio (ex: fatos e dimens√µes) |

- As sa√≠das das transforma√ß√µes da **Staging** v√£o para a camada **Silver**, e os modelos finais do **Mart** v√£o para a camada **Gold** no MinIO.

- DBT se conectar√° ao Trino, que por sua vez usa o Hive Metastore para interpretar os dados.

---

### Fase 6 ‚Äì Orquestra√ß√£o com Airflow

- Criar um DAG no Airflow com as seguintes tasks:

1. **Gera√ß√£o de dados**
2. **Upload para MinIO (Bronze)**
3. **Valida√ß√£o com DuckDB**
4. **Registro de metadados no Hive**
5. **Consultas explorat√≥rias com Trino**
6. **Execu√ß√£o dos modelos DBT (gerando Silver e Gold)**
7. **(Opcional) Gera√ß√£o de dashboards no Superset ou Metabase**

---

## ‚úÖ Tecnologias Finais

- **Python**
- **MinIO (Data Lake com camadas Bronze, Silver e Gold)**
- **Hive Metastore**
- **DuckDB**
- **Trino (Presto)**
- **DBT**
- **Apache Airflow**
- **(Opcional) Apache Superset ou Metabase**

---

## üí¨ Observa√ß√µes

- Todas as ferramentas utilizadas devem ser **open source** e de uso livre.
- A complexidade e o n√≠vel de detalhamento s√£o graduais: o foco √© o aprendizado.
- A escolha do contexto dos dados fica livre para o grupo.

---

**Bons estudos e bom projeto! üöÄ**
